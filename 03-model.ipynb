{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-23T20:47:41.720194Z",
     "start_time": "2025-07-23T20:47:41.693246Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import softclustering as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import socceraction.spadl as spadl\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "e4e0a9ff891dabc4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Concatenate actions of all games in one DataFrame.",
   "id": "228a4a3ac4e36d4a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T20:47:42.082178Z",
     "start_time": "2025-07-23T20:47:41.725711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "datafolder = \"data\"\n",
    "fifa2018h5 = os.path.join(datafolder, \"spadl-fifa2018.h5\")\n",
    "games = pd.read_hdf(fifa2018h5, key=\"games\")\n",
    "with pd.HDFStore(fifa2018h5) as store:\n",
    "    actions = []  #list of DataFrames\n",
    "    for game in tqdm.tqdm(games.itertuples()):\n",
    "        game_action = store[f\"actions/game_{game.game_id}\"]\n",
    "        game_action = spadl.play_left_to_right(game_action, game.home_team_id)\n",
    "        game_action[\"is_home\"] = game_action[\"team_id\"] == game.home_team_id\n",
    "        actions.append(game_action)\n",
    "    actions = pd.concat(actions)\n",
    "    actions.drop(\"original_event_id\", axis=1, inplace=True)\n",
    "    actions = pd.merge(actions, spadl.config.actiontypes_df(), how=\"left\")"
   ],
   "id": "71934fdfa2402fa6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "64it [00:00, 202.37it/s]\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T20:47:42.162100Z",
     "start_time": "2025-07-23T20:47:42.091234Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def consolidate(actions):\n",
    "    #actions.fillna(0, inplace=True)\n",
    "\n",
    "    #Consolidate corner_short and corner_crossed\n",
    "    corner_idx = actions.type_name.str.contains(\"corner\")\n",
    "    actions[\"type_name\"] = actions[\"type_name\"].mask(corner_idx, \"corner\")\n",
    "\n",
    "    #Consolidate freekick_short, freekick_crossed, and shot_freekick\n",
    "    freekick_idx = actions.type_name.str.contains(\"freekick\")\n",
    "    actions[\"type_name\"] = actions[\"type_name\"].mask(freekick_idx, \"freekick\")\n",
    "\n",
    "    #Consolidate keeper_claim, keeper_punch, keeper_save, keeper_pick_up\n",
    "    keeper_idx = actions.type_name.str.contains(\"keeper\")\n",
    "    actions[\"type_name\"] = actions[\"type_name\"].mask(keeper_idx, \"keeper_action\")\n",
    "\n",
    "    actions[\"start_x\"] = actions[\"start_x\"].mask(actions.type_name == \"shot_penalty\", 94.5)\n",
    "    actions[\"start_y\"] = actions[\"start_y\"].mask(actions.type_name == \"shot_penalty\", 34)\n",
    "\n",
    "    return actions\n",
    "\n",
    "\n",
    "actions = consolidate(actions)"
   ],
   "id": "533326ea9e5b5f1c",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T20:47:42.183534Z",
     "start_time": "2025-07-23T20:47:42.171209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Actions of Team France matches.\n",
    "len(actions[actions[\"team_id\"] == 771])"
   ],
   "id": "1791e14d37fb5174",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6829"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T20:47:42.209049Z",
     "start_time": "2025-07-23T20:47:42.192425Z"
    }
   },
   "cell_type": "code",
   "source": "actions.groupby(\"type_name\").size()",
   "id": "4eb9f50ea571275d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type_name\n",
       "bad_touch         1547\n",
       "clearance         2074\n",
       "corner             558\n",
       "cross             1305\n",
       "dribble          52731\n",
       "foul              1876\n",
       "freekick          1272\n",
       "goalkick           677\n",
       "interception      1681\n",
       "keeper_action      584\n",
       "pass             56438\n",
       "shot              1556\n",
       "shot_penalty        68\n",
       "tackle            1830\n",
       "take_on           2109\n",
       "throw_in          2178\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "As suggested in SoccerMix, add noise on the starting and ending locations, but only on those actions that we can visually note a predefined pattern.\n",
    "* *Add noise in both start and end locations*:\n",
    "    * Cross\n",
    "    * Shot\n",
    "    * Keeper_action\n",
    "* *Only on start locations*:\n",
    "    * Clearance\n",
    "    * Goal kick\n",
    "* *Only on end locations*:\n",
    "    * Corner\n",
    "    * Freekick\n",
    "    * Shot_penalty"
   ],
   "id": "f365f4a57e669f5c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T20:47:42.263804Z",
     "start_time": "2025-07-23T20:47:42.236064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def add_noise(actions):\n",
    "    # Start locations\n",
    "    start_list = [\"cross\", \"shot\", \"keeper_action\", \"clearance\", \"goalkick\"]\n",
    "    mask = actions[\"type_name\"].isin(start_list)\n",
    "    noise = np.random.normal(0, 0.5, size=actions.loc[mask, [\"start_x\", \"start_y\"]].shape)\n",
    "    actions.loc[mask, [\"start_x\", \"start_y\"]] += noise\n",
    "\n",
    "    # End locations\n",
    "    end_list = [\"cross\", \"shot\", \"keeper_action\", \"corner\", \"freekick\", \"shot_penalty\"]\n",
    "    mask = actions[\"type_name\"].isin(end_list)\n",
    "    noise = np.random.normal(0, 0.5, size=actions.loc[mask, [\"end_x\", \"end_y\"]].shape)\n",
    "    actions.loc[mask, [\"end_x\", \"end_y\"]] += noise\n",
    "\n",
    "    return actions\n",
    "\n",
    "\n",
    "actions = add_noise(actions)"
   ],
   "id": "9b595325cb6d6b7b",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T20:47:42.292351Z",
     "start_time": "2025-07-23T20:47:42.281772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # display event locations with noise\n",
    "# corrected_actions = [\"cross\", \"shot\", \"keeper_action\", \"clearance\", \"goalkick\",\"corner\", \"freekick\", \"shot_penalty\"]\n",
    "# for actiontype in corrected_actions:\n",
    "#     actions[actions.type_name == actiontype].plot.scatter(\n",
    "#         x=\"start_x\",\n",
    "#         y=\"start_y\",\n",
    "#         title = f\"Start Location: {actiontype}\",\n",
    "#         figsize = (6,4)\n",
    "#     )\n",
    "#     plt.show()\n",
    "#     actions[actions.type_name == actiontype].plot.scatter(\n",
    "#         x=\"end_x\",\n",
    "#         y=\"end_y\",\n",
    "#         title = f\"End Location: {actiontype}\",\n",
    "#         figsize = (6,4)\n",
    "#     )\n",
    "#     plt.show()"
   ],
   "id": "96ef05afa181356c",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Compute the angle of the direction of the action with respect with the x-axis (pitch's length) a\n",
    "$$\\tan \\theta = \\frac{y_{end} - y_{start}}{x_{end} - x_{start}}$$"
   ],
   "id": "8a99a2a13347dd0a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T20:47:42.336636Z",
     "start_time": "2025-07-23T20:47:42.304634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "actions[\"angle\"] = np.arctan2(actions.end_y - actions.start_y, actions.end_x - actions.start_x)\n",
    "actions[\"cos_angle\"] = np.cos(actions[\"angle\"])\n",
    "actions[\"sin_angle\"] = np.sin(actions[\"angle\"])\n",
    "actions[[\"angle\", \"cos_angle\", \"sin_angle\"]].describe()"
   ],
   "id": "69c78aee6b06747",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               angle      cos_angle      sin_angle\n",
       "count  128484.000000  128484.000000  128484.000000\n",
       "mean        0.062299       0.313633      -0.005792\n",
       "std         1.464611       0.678503       0.664260\n",
       "min        -3.139783      -1.000000      -1.000000\n",
       "25%        -0.969342      -0.183971      -0.647648\n",
       "50%         0.000000       0.525493       0.000000\n",
       "75%         1.076271       0.954549       0.624695\n",
       "max         3.141593       1.000000       1.000000"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>angle</th>\n",
       "      <th>cos_angle</th>\n",
       "      <th>sin_angle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>128484.000000</td>\n",
       "      <td>128484.000000</td>\n",
       "      <td>128484.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.062299</td>\n",
       "      <td>0.313633</td>\n",
       "      <td>-0.005792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.464611</td>\n",
       "      <td>0.678503</td>\n",
       "      <td>0.664260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.139783</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.969342</td>\n",
       "      <td>-0.183971</td>\n",
       "      <td>-0.647648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.525493</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.076271</td>\n",
       "      <td>0.954549</td>\n",
       "      <td>0.624695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.141593</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T20:47:42.383205Z",
     "start_time": "2025-07-23T20:47:42.363892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mask = (actions[\"type_name\"]==\"throw_in\") & (actions[\"team_id\"]==771)\n",
    "data_loc = actions[mask][[\"start_x\", \"start_y\"]]\n",
    "data_loc.describe()"
   ],
   "id": "2877a86b1aed5203",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          start_x     start_y\n",
       "count  116.000000  116.000000\n",
       "mean    60.918103   38.030172\n",
       "std     26.507723   33.145853\n",
       "min      9.187500    0.425000\n",
       "25%     38.937500    0.425000\n",
       "50%     64.750000   66.725000\n",
       "75%     85.531250   67.575000\n",
       "max    101.937500   67.575000"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_x</th>\n",
       "      <th>start_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>116.000000</td>\n",
       "      <td>116.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>60.918103</td>\n",
       "      <td>38.030172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>26.507723</td>\n",
       "      <td>33.145853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.187500</td>\n",
       "      <td>0.425000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>38.937500</td>\n",
       "      <td>0.425000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>64.750000</td>\n",
       "      <td>66.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>85.531250</td>\n",
       "      <td>67.575000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>101.937500</td>\n",
       "      <td>67.575000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T20:47:42.659125Z",
     "start_time": "2025-07-23T20:47:42.419114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "K_gauss = 6\n",
    "gauss_clusters = [sc.MultivariateGaussian() for j in range(K_gauss)]\n",
    "gaussian_model = sc.MixtureModel(gauss_clusters)\n",
    "_ = gaussian_model.fit_classical_EM(data_loc, verbose=True)"
   ],
   "id": "b462832fe28249fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data log-likelihood at iter 0: -661.97\n",
      "Data log-likelihood at iter 1: -660.48\n",
      "Data log-likelihood at iter 2: -660.00\n",
      "Data log-likelihood at iter 3: -659.66\n",
      "Data log-likelihood at iter 4: -659.36\n",
      "Data log-likelihood at iter 5: -659.10\n",
      "Data log-likelihood at iter 6: -658.87\n",
      "Data log-likelihood at iter 7: -658.68\n",
      "Data log-likelihood at iter 8: -658.50\n",
      "Data log-likelihood at iter 9: -658.33\n",
      "Data log-likelihood at iter 10: -658.15\n",
      "Data log-likelihood at iter 11: -657.96\n",
      "Data log-likelihood at iter 12: -657.75\n",
      "Data log-likelihood at iter 13: -657.52\n",
      "Data log-likelihood at iter 14: -657.27\n",
      "Data log-likelihood at iter 15: -657.01\n",
      "Data log-likelihood at iter 16: -656.71\n",
      "Data log-likelihood at iter 17: -656.38\n",
      "Data log-likelihood at iter 18: -655.96\n",
      "Data log-likelihood at iter 19: -655.33\n",
      "Data log-likelihood at iter 20: -653.98\n",
      "Data log-likelihood at iter 21: -649.49\n",
      "Data log-likelihood at iter 22: -621.18\n",
      "Data log-likelihood at iter 23: -512.85\n",
      "Data log-likelihood at iter 24: -448.19\n",
      "Data log-likelihood at iter 25: -374.74\n",
      "Data log-likelihood at iter 26: -204.93\n",
      "Data log-likelihood at iter 27: -188.96\n",
      "Data log-likelihood at iter 28: -188.82\n",
      "Data log-likelihood at iter 29: -188.70\n",
      "Data log-likelihood at iter 30: -188.60\n",
      "Data log-likelihood at iter 31: -188.52\n",
      "Data log-likelihood at iter 32: -188.46\n",
      "Data log-likelihood at iter 33: -188.42\n",
      "Data log-likelihood at iter 34: -188.40\n",
      "Data log-likelihood at iter 35: -188.39\n",
      "Data log-likelihood at iter 36: -188.39\n",
      "Data log-likelihood at iter 37: -188.39\n",
      "Data log-likelihood at iter 38: -188.39\n",
      "Data log-likelihood at iter 39: -188.39\n",
      "Data log-likelihood at iter 40: -188.39\n",
      "Data log-likelihood at iter 41: -188.39\n",
      "Data log-likelihood at iter 42: -188.39\n",
      "Data log-likelihood at iter 43: -188.39\n",
      "Data log-likelihood at iter 44: -188.39\n",
      "Data log-likelihood at iter 45: -188.39\n",
      "Converged at iter 45: Delta LL=5.553e-07\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T20:47:42.713047Z",
     "start_time": "2025-07-23T20:47:42.692687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for cluster in gaussian_model.components:\n",
    "    print(cluster)"
   ],
   "id": "b1fa68da78131cb5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultivariateGaussian(d=2, mean=[20.79851758  1.275     ], cov=[[3.22870946e+01 0.00000000e+00]\n",
      " [0.00000000e+00 1.00000000e-09]])\n",
      "MultivariateGaussian(d=2, mean=[56.52770319 67.05891077], cov=[[60.89060947 -2.50906618]\n",
      " [-2.50906618  0.17232775]])\n",
      "MultivariateGaussian(d=2, mean=[64.98333333  0.425     ], cov=[[ 6.78174462e+02 -3.69778549e-32]\n",
      " [-6.76503222e-32  1.00000000e-09]])\n",
      "MultivariateGaussian(d=2, mean=[83.35255752 67.439553  ], cov=[[94.31317171 -0.65660458]\n",
      " [-0.65660458  0.09678406]])\n",
      "MultivariateGaussian(d=2, mean=[25.77454388 67.10292548], cov=[[106.56115203  -1.34938545]\n",
      " [ -1.34938545   0.17840899]])\n",
      "MultivariateGaussian(d=2, mean=[64.65820656  1.275     ], cov=[[3.52130206e+02 1.03537994e-30]\n",
      " [9.38905311e-31 1.00000000e-09]])\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T20:47:43.668800Z",
     "start_time": "2025-07-23T20:47:42.795014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_dir = actions[mask][[\"cos_angle\",\"sin_angle\"]]\n",
    "K_vm = 4\n",
    "vm_clusters = [sc.VonMises() for j in range(K_vm)]\n",
    "vonmises_model = sc.MixtureModel(vm_clusters)\n",
    "_ = vonmises_model.fit_classical_EM(data_dir, verbose=True)"
   ],
   "id": "6f6b97de15e1de30",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data log-likelihood at iter 0: -183.78\n",
      "Data log-likelihood at iter 1: -183.20\n",
      "Data log-likelihood at iter 2: -183.08\n",
      "Data log-likelihood at iter 3: -183.04\n",
      "Data log-likelihood at iter 4: -183.01\n",
      "Data log-likelihood at iter 5: -182.99\n",
      "Data log-likelihood at iter 6: -182.98\n",
      "Data log-likelihood at iter 7: -182.97\n",
      "Data log-likelihood at iter 8: -182.96\n",
      "Data log-likelihood at iter 9: -182.96\n",
      "Data log-likelihood at iter 10: -182.95\n",
      "Data log-likelihood at iter 11: -182.94\n",
      "Data log-likelihood at iter 12: -182.94\n",
      "Data log-likelihood at iter 13: -182.93\n",
      "Data log-likelihood at iter 14: -182.93\n",
      "Data log-likelihood at iter 15: -182.92\n",
      "Data log-likelihood at iter 16: -182.92\n",
      "Data log-likelihood at iter 17: -182.92\n",
      "Data log-likelihood at iter 18: -182.91\n",
      "Data log-likelihood at iter 19: -182.91\n",
      "Data log-likelihood at iter 20: -182.91\n",
      "Data log-likelihood at iter 21: -182.90\n",
      "Data log-likelihood at iter 22: -182.90\n",
      "Data log-likelihood at iter 23: -182.90\n",
      "Data log-likelihood at iter 24: -182.90\n",
      "Data log-likelihood at iter 25: -182.89\n",
      "Data log-likelihood at iter 26: -182.89\n",
      "Data log-likelihood at iter 27: -182.89\n",
      "Data log-likelihood at iter 28: -182.89\n",
      "Data log-likelihood at iter 29: -182.89\n",
      "Data log-likelihood at iter 30: -182.89\n",
      "Data log-likelihood at iter 31: -182.88\n",
      "Data log-likelihood at iter 32: -182.88\n",
      "Data log-likelihood at iter 33: -182.88\n",
      "Data log-likelihood at iter 34: -182.88\n",
      "Data log-likelihood at iter 35: -182.88\n",
      "Data log-likelihood at iter 36: -182.88\n",
      "Data log-likelihood at iter 37: -182.88\n",
      "Data log-likelihood at iter 38: -182.88\n",
      "Data log-likelihood at iter 39: -182.88\n",
      "Data log-likelihood at iter 40: -182.87\n",
      "Data log-likelihood at iter 41: -182.87\n",
      "Data log-likelihood at iter 42: -182.87\n",
      "Data log-likelihood at iter 43: -182.87\n",
      "Data log-likelihood at iter 44: -182.87\n",
      "Data log-likelihood at iter 45: -182.87\n",
      "Data log-likelihood at iter 46: -182.87\n",
      "Data log-likelihood at iter 47: -182.87\n",
      "Data log-likelihood at iter 48: -182.87\n",
      "Data log-likelihood at iter 49: -182.87\n",
      "Data log-likelihood at iter 50: -182.87\n",
      "Data log-likelihood at iter 51: -182.87\n",
      "Data log-likelihood at iter 52: -182.87\n",
      "Data log-likelihood at iter 53: -182.87\n",
      "Data log-likelihood at iter 54: -182.87\n",
      "Data log-likelihood at iter 55: -182.87\n",
      "Data log-likelihood at iter 56: -182.87\n",
      "Data log-likelihood at iter 57: -182.87\n",
      "Data log-likelihood at iter 58: -182.87\n",
      "Data log-likelihood at iter 59: -182.87\n",
      "Data log-likelihood at iter 60: -182.87\n",
      "Data log-likelihood at iter 61: -182.87\n",
      "Data log-likelihood at iter 62: -182.87\n",
      "Data log-likelihood at iter 63: -182.87\n",
      "Data log-likelihood at iter 64: -182.87\n",
      "Data log-likelihood at iter 65: -182.87\n",
      "Data log-likelihood at iter 66: -182.87\n",
      "Data log-likelihood at iter 67: -182.87\n",
      "Data log-likelihood at iter 68: -182.87\n",
      "Data log-likelihood at iter 69: -182.87\n",
      "Data log-likelihood at iter 70: -182.86\n",
      "Data log-likelihood at iter 71: -182.86\n",
      "Data log-likelihood at iter 72: -182.86\n",
      "Data log-likelihood at iter 73: -182.86\n",
      "Data log-likelihood at iter 74: -182.86\n",
      "Data log-likelihood at iter 75: -182.86\n",
      "Data log-likelihood at iter 76: -182.86\n",
      "Data log-likelihood at iter 77: -182.86\n",
      "Data log-likelihood at iter 78: -182.86\n",
      "Data log-likelihood at iter 79: -182.86\n",
      "Data log-likelihood at iter 80: -182.86\n",
      "Data log-likelihood at iter 81: -182.86\n",
      "Data log-likelihood at iter 82: -182.86\n",
      "Data log-likelihood at iter 83: -182.86\n",
      "Data log-likelihood at iter 84: -182.86\n",
      "Data log-likelihood at iter 85: -182.86\n",
      "Data log-likelihood at iter 86: -182.86\n",
      "Data log-likelihood at iter 87: -182.86\n",
      "Data log-likelihood at iter 88: -182.86\n",
      "Data log-likelihood at iter 89: -182.86\n",
      "Data log-likelihood at iter 90: -182.86\n",
      "Data log-likelihood at iter 91: -182.86\n",
      "Data log-likelihood at iter 92: -182.86\n",
      "Data log-likelihood at iter 93: -182.86\n",
      "Data log-likelihood at iter 94: -182.86\n",
      "Data log-likelihood at iter 95: -182.86\n",
      "Data log-likelihood at iter 96: -182.86\n",
      "Data log-likelihood at iter 97: -182.86\n",
      "Data log-likelihood at iter 98: -182.86\n",
      "Data log-likelihood at iter 99: -182.86\n",
      "Data log-likelihood at iter 100: -182.86\n",
      "Data log-likelihood at iter 101: -182.86\n",
      "Data log-likelihood at iter 102: -182.86\n",
      "Data log-likelihood at iter 103: -182.86\n",
      "Data log-likelihood at iter 104: -182.86\n",
      "Data log-likelihood at iter 105: -182.86\n",
      "Data log-likelihood at iter 106: -182.86\n",
      "Data log-likelihood at iter 107: -182.86\n",
      "Data log-likelihood at iter 108: -182.86\n",
      "Data log-likelihood at iter 109: -182.86\n",
      "Data log-likelihood at iter 110: -182.86\n",
      "Data log-likelihood at iter 111: -182.86\n",
      "Data log-likelihood at iter 112: -182.86\n",
      "Data log-likelihood at iter 113: -182.86\n",
      "Data log-likelihood at iter 114: -182.86\n",
      "Data log-likelihood at iter 115: -182.86\n",
      "Data log-likelihood at iter 116: -182.86\n",
      "Data log-likelihood at iter 117: -182.86\n",
      "Data log-likelihood at iter 118: -182.86\n",
      "Data log-likelihood at iter 119: -182.86\n",
      "Data log-likelihood at iter 120: -182.86\n",
      "Data log-likelihood at iter 121: -182.86\n",
      "Data log-likelihood at iter 122: -182.86\n",
      "Data log-likelihood at iter 123: -182.86\n",
      "Data log-likelihood at iter 124: -182.86\n",
      "Data log-likelihood at iter 125: -182.86\n",
      "Data log-likelihood at iter 126: -182.86\n",
      "Data log-likelihood at iter 127: -182.86\n",
      "Data log-likelihood at iter 128: -182.86\n",
      "Data log-likelihood at iter 129: -182.86\n",
      "Data log-likelihood at iter 130: -182.86\n",
      "Data log-likelihood at iter 131: -182.86\n",
      "Data log-likelihood at iter 132: -182.86\n",
      "Data log-likelihood at iter 133: -182.86\n",
      "Data log-likelihood at iter 134: -182.86\n",
      "Data log-likelihood at iter 135: -182.86\n",
      "Data log-likelihood at iter 136: -182.86\n",
      "Data log-likelihood at iter 137: -182.86\n",
      "Data log-likelihood at iter 138: -182.86\n",
      "Data log-likelihood at iter 139: -182.86\n",
      "Data log-likelihood at iter 140: -182.86\n",
      "Data log-likelihood at iter 141: -182.86\n",
      "Data log-likelihood at iter 142: -182.86\n",
      "Data log-likelihood at iter 143: -182.86\n",
      "Data log-likelihood at iter 144: -182.86\n",
      "Data log-likelihood at iter 145: -182.86\n",
      "Data log-likelihood at iter 146: -182.86\n",
      "Data log-likelihood at iter 147: -182.86\n",
      "Data log-likelihood at iter 148: -182.86\n",
      "Data log-likelihood at iter 149: -182.86\n",
      "Data log-likelihood at iter 150: -182.86\n",
      "Data log-likelihood at iter 151: -182.86\n",
      "Data log-likelihood at iter 152: -182.86\n",
      "Data log-likelihood at iter 153: -182.86\n",
      "Data log-likelihood at iter 154: -182.86\n",
      "Data log-likelihood at iter 155: -182.86\n",
      "Data log-likelihood at iter 156: -182.86\n",
      "Data log-likelihood at iter 157: -182.86\n",
      "Data log-likelihood at iter 158: -182.86\n",
      "Data log-likelihood at iter 159: -182.86\n",
      "Data log-likelihood at iter 160: -182.86\n",
      "Data log-likelihood at iter 161: -182.86\n",
      "Data log-likelihood at iter 162: -182.86\n",
      "Data log-likelihood at iter 163: -182.86\n",
      "Data log-likelihood at iter 164: -182.86\n",
      "Data log-likelihood at iter 165: -182.86\n",
      "Data log-likelihood at iter 166: -182.86\n",
      "Data log-likelihood at iter 167: -182.86\n",
      "Data log-likelihood at iter 168: -182.86\n",
      "Data log-likelihood at iter 169: -182.86\n",
      "Data log-likelihood at iter 170: -182.86\n",
      "Data log-likelihood at iter 171: -182.86\n",
      "Data log-likelihood at iter 172: -182.86\n",
      "Data log-likelihood at iter 173: -182.86\n",
      "Data log-likelihood at iter 174: -182.86\n",
      "Data log-likelihood at iter 175: -182.86\n",
      "Data log-likelihood at iter 176: -182.86\n",
      "Data log-likelihood at iter 177: -182.86\n",
      "Converged at iter 177: Delta LL=9.739e-07\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T20:47:43.689481Z",
     "start_time": "2025-07-23T20:47:43.678227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for cluster in vonmises_model.components:\n",
    "    print(cluster)"
   ],
   "id": "9192aa6ab975c28e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VonMises(loc=-5.7ยบ, kappa=12.692)\n",
      "VonMises(loc=173.4ยบ, kappa=12.948)\n",
      "VonMises(loc=-103.3ยบ, kappa=4.191)\n",
      "VonMises(loc=93.3ยบ, kappa=2.296)\n"
     ]
    }
   ],
   "execution_count": 63
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
